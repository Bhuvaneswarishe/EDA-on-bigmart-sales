# -*- coding: utf-8 -*-
"""bigmart Sales Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1psYoDuKmmTTq51Zp0b_7YMZziayFFQOC
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

df1=pd.read_csv('/content/bigmart.csv')

df1.head()

df1.shape

df1.isnull().sum()

df1.info()

df1['Item_Weight']=df1['Item_Weight'].fillna(df1['Item_Weight'].mean())

df1['Outlet_Size']=df1['Outlet_Size'].fillna(df1['Outlet_Size'].mode()[0])

df1.isnull().sum()

df1.describe()

fat_content_mapping = {
    'low fat': 'Low Fat',
    'LF': 'Low Fat',
    'reg': 'Regular',
    'low fat':'Low Fat',
    'reg':'Regular'
}

df1['Item_Fat_Content'] = df1['Item_Fat_Content'].replace(fat_content_mapping)

import seaborn as sns
sns.countplot(x='Item_Fat_Content',data=df1)

sns.countplot(x="Item_Type",data=df1)
plt.xlabel('Item_Type', fontsize=14)
plt.show()

df1.drop(columns= ['Outlet_Identifier'],inplace=True)

from sklearn.preprocessing import LabelEncoder as le

df1['Item_Fat_Content']=le().fit_transform(df1['Item_Fat_Content'])
df1['Outlet_Size']=le().fit_transform(df1['Outlet_Size'])
df1['Outlet_Location_Type']=le().fit_transform(df1['Outlet_Location_Type'])
df1['Item_Type']=le().fit_transform(df1['Item_Type'])
df1['Outlet_Type']=le().fit_transform(df1['Outlet_Type'])

df1.drop(columns= ['Item_Identifier'],inplace=True)

df1.head()

sns.countplot(x="Item_Type",data=df1)

import matplotlib.pyplot as plt

corr_matrix=df1.corr()
plt.figure(figsize=(10,8))
sns.heatmap(corr_matrix,annot=True,cmap='coolwarm')
plt.title('Correlation Analysis')
plt.show()

plt.figure(figsize=(14, 8))
sns.countplot(x='Item_Type', hue='Item_Fat_Content', data=df1
              , palette='coolwarm')
plt.xticks(rotation=90)
plt.title('Distribution of Fat Content across Item Types')
plt.xlabel('Item Type')
plt.ylabel('Count')
plt.show()

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score,mean_squared_error,accuracy_score

df1.drop(columns='Item_Identifier',inplace=True)

df1.head()

from sklearn.ensemble import RandomForestRegressor

from sklearn.metrics import mean_squared_error, r2_score

from sklearn.metrics import accuracy_score

X = df1.drop(columns=['Item_Outlet_Sales'])
y = df1['Item_Outlet_Sales']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model selection and training
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# Evaluation
y_pred = model.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f'RMSE: {rmse}')
r2 = r2_score(y_test, y_pred)
print(r2)